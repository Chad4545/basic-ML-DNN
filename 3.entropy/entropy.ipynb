{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- https://youtu.be/zJmbkp9TCXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification의 Loss function으로는 CE를 주로 사용합니다.\n",
    "\n",
    "# 두 분포의 차이를 줄이기 위해 KL-divergence를 최소화 합니다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- 이와 같은 말을 너무나도 많이 접하게 되고, 그냥 자연스럽게 그런가보다 하고 넘어가게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 과연 이게 뭘까..?\n",
    "\n",
    "## Cross_entropy\n",
    "\n",
    "- 일반적으로, softmax의 loss 함수로써 Cross_entropy를 쓴다.\n",
    "\n",
    "- 과연 이게 뭘까 ?\n",
    "\n",
    "--- \n",
    "\n",
    "- Logistic Loss == Multinomial Logistic Loss == Cross-Entropy loss\n",
    "- 주로, multi-class classification task의 loss로 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ce1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy\n",
    "\n",
    "- Cross_entropy를 알기 위해선, 먼저 entropy를 알아야 한다.\n",
    "- entropy란 정보(데이터)를 최적으로 인코딩하기 위해 필요한 bit수를 의미한다.\n",
    "- bit수가 크다는 것은 그만큼 정보량도 많음을 의미\n",
    "- 여기서 정보량 ==  entropy는  최적으로 압축하고 압축한 bit의 수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='ce2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 1)\n",
    "- 예를 들어, 요일(weekday) 정보를  bit로 나타내기 위해서 \n",
    "- 7일 이면 7개니깐 7bit가 필요 한게 아니라, 2의 3승은 8이니깐 3비트가 필요합니다(bit는 log2의 N를 따름).\n",
    "\n",
    "      - 월(000), 화(001), 수(010), 목(011),금(100), 토(101), 일(110)... \n",
    " \n",
    " \n",
    " - 최소 8가지 정보를 나타내는데  3비트면 충분합니다.\n",
    " - 다시 말하자면, 요일의 정보량은 3비트인 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example 2)\n",
    "\n",
    "- 각 사건의 발생확률이 다르다면??\n",
    "\n",
    "      예를 들어, 월,화,수,목,금,토,일 의 발생확률은 1/7로 같지만, 그렇지 않은 사건들에 대한 entropy는 어떻게 될까?\n",
    "      \n",
    "---\n",
    "\n",
    "#### 1. 40개의 문자, 모든 같은 확률\n",
    "-  40개의 문자(A,B,C,...,1,2,3,...,14)를 bit로 전송한다.\n",
    "-  40개의 사건이 모두 같은 확률로 발생한다면 -> log2의 40 = 5.3 -> 6bit\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- 그런데, A,B,C,D가 90%(각각 22.5%의 )확률로 발생되고, 나머지 36개의 문자는 10%의 확률로 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이해를 돕기 위한 추가설명\n",
    "\n",
    "- 예를 들자면, bit를 돈이라고 가정.\n",
    "- 저는 90% 술을 먹어요, 10%로 디저트 카페에 가서 마카롱을 먹어요.\n",
    "- 쓰는 돈(bit=cost)을 줄이기 위해서는 술을 자주 마시니깐 소주(cost가 낮은..)를 먹어야겠죠?\n",
    "- 마카롱은 10%의 확률로 사먹으니깐 먹을때 먹더라도 좀 비싼거 먹어도 되겠죠? (자주 안먹을꺼니깐...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 40개의 문자로 돌아가서 ( 발생 확률이 다른 경우)\n",
    "\n",
    "- ABCD가 90% 발생하고 나머지가 10%로 발생하는데\n",
    "- ABCD가 많이 발생하니깐 여기에 대한 cost를 줄이기 위해서는, bit를 조금만 쓰고 싶은겁니다.\n",
    "\n",
    "---\n",
    "\n",
    "    - 1st bit = ABCD or not\n",
    "    ex) 1000... <- ABCD 중에 하나           -> A,B,C,D 중에 무엇인지에 대해 표현하기 위해 추가적으로 2bit필요\n",
    "        0000... <- ABCD 가 아님             -> 나머지 36개 중에 무엇인지에 대해 표현하기 위해 추가적으로 6bit필요 (log2의 36)\n",
    "\n",
    "---\n",
    "\n",
    "-   0.9 x 3 + 0.1 x 7 = 3.4 비트 필요 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 요약\n",
    "\n",
    "- 사건의 발생확률이 다른경우 단순히 log2의 N으로 entropy를 구하는 것 보다\n",
    "\n",
    "- 각 사건의 발생확률을 따져서 entropy를 구한다면, 더 적은 bit로 표현가능\n",
    "\n",
    "- 다시 말하자면, 각각 label(사건)의 확률분포가 중요한 역할\n",
    "\n",
    "- entropy 는 각 label의 확률분포의 함수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- 여기서 yi는 각 label의 확률을 뜻하고(위 40개 문자에서 label A,B,C,D는 0.9로 표현, 엄밀히 말하자면 0.225...) \n",
    "\n",
    "- log(1/yi)는 단순히 label 갯수인 N을 넣는 것이 아니라, 각 label에 비례하는 log(1/yi)값을 넣어줌\n",
    "\n",
    "  (위 40개 문자에서 ABCD인 경우 3, 그 외 6)\n",
    "<img src='ce2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다시 적용해보면\n",
    "\n",
    "- 4 x 0.225 x log(1/0.225) :  A, B, C, D\n",
    "- 36 x 0.0028 x 1og(1/0.0028) : 그 외\n",
    "\n",
    "---\n",
    "\n",
    "이를 더해주면 최종적으로 2.72 bit (6bit -> 3.3bit -> 2.72bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결국\n",
    "### entropy는 정보량을 최적으로 압축시켰을때 나오는 bit 수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
